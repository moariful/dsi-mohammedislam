{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "263eb813-da45-48cf-9a8f-9da76c18e470"
   },
   "source": [
    "# Project 2\n",
    "## Step 1: Explore data\n",
    "\n",
    "##### Load your data in using Pandas and start to explore. Save all of your early exploration code here and include in your final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "b733d2fe-6d33-41dd-a3fc-5dfe9d71d91f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb_original = pd.read_csv(\"../assets/billboard.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 317 entries, 0 to 316\n",
      "Data columns (total 83 columns):\n",
      "year               317 non-null int64\n",
      "artist.inverted    317 non-null object\n",
      "track              317 non-null object\n",
      "time               317 non-null object\n",
      "genre              317 non-null object\n",
      "date.entered       317 non-null object\n",
      "date.peaked        317 non-null object\n",
      "x1st.week          317 non-null int64\n",
      "x2nd.week          312 non-null float64\n",
      "x3rd.week          307 non-null float64\n",
      "x4th.week          300 non-null float64\n",
      "x5th.week          292 non-null float64\n",
      "x6th.week          280 non-null float64\n",
      "x7th.week          269 non-null float64\n",
      "x8th.week          260 non-null float64\n",
      "x9th.week          253 non-null float64\n",
      "x10th.week         244 non-null float64\n",
      "x11th.week         236 non-null float64\n",
      "x12th.week         222 non-null float64\n",
      "x13th.week         210 non-null float64\n",
      "x14th.week         204 non-null float64\n",
      "x15th.week         197 non-null float64\n",
      "x16th.week         182 non-null float64\n",
      "x17th.week         177 non-null float64\n",
      "x18th.week         166 non-null float64\n",
      "x19th.week         156 non-null float64\n",
      "x20th.week         146 non-null float64\n",
      "x21st.week         65 non-null float64\n",
      "x22nd.week         55 non-null float64\n",
      "x23rd.week         48 non-null float64\n",
      "x24th.week         46 non-null float64\n",
      "x25th.week         38 non-null float64\n",
      "x26th.week         36 non-null float64\n",
      "x27th.week         29 non-null float64\n",
      "x28th.week         24 non-null float64\n",
      "x29th.week         20 non-null float64\n",
      "x30th.week         20 non-null float64\n",
      "x31st.week         19 non-null float64\n",
      "x32nd.week         18 non-null float64\n",
      "x33rd.week         12 non-null float64\n",
      "x34th.week         10 non-null float64\n",
      "x35th.week         9 non-null float64\n",
      "x36th.week         9 non-null float64\n",
      "x37th.week         9 non-null float64\n",
      "x38th.week         8 non-null float64\n",
      "x39th.week         8 non-null float64\n",
      "x40th.week         7 non-null float64\n",
      "x41st.week         7 non-null float64\n",
      "x42nd.week         6 non-null float64\n",
      "x43rd.week         6 non-null float64\n",
      "x44th.week         6 non-null float64\n",
      "x45th.week         5 non-null float64\n",
      "x46th.week         5 non-null float64\n",
      "x47th.week         5 non-null float64\n",
      "x48th.week         4 non-null float64\n",
      "x49th.week         4 non-null float64\n",
      "x50th.week         4 non-null float64\n",
      "x51st.week         4 non-null float64\n",
      "x52nd.week         4 non-null float64\n",
      "x53rd.week         4 non-null float64\n",
      "x54th.week         2 non-null float64\n",
      "x55th.week         2 non-null float64\n",
      "x56th.week         2 non-null float64\n",
      "x57th.week         2 non-null float64\n",
      "x58th.week         2 non-null float64\n",
      "x59th.week         2 non-null float64\n",
      "x60th.week         2 non-null float64\n",
      "x61st.week         2 non-null float64\n",
      "x62nd.week         2 non-null float64\n",
      "x63rd.week         2 non-null float64\n",
      "x64th.week         2 non-null float64\n",
      "x65th.week         1 non-null float64\n",
      "x66th.week         0 non-null float64\n",
      "x67th.week         0 non-null float64\n",
      "x68th.week         0 non-null float64\n",
      "x69th.week         0 non-null float64\n",
      "x70th.week         0 non-null float64\n",
      "x71st.week         0 non-null float64\n",
      "x72nd.week         0 non-null float64\n",
      "x73rd.week         0 non-null float64\n",
      "x74th.week         0 non-null float64\n",
      "x75th.week         0 non-null float64\n",
      "x76th.week         0 non-null float64\n",
      "dtypes: float64(75), int64(2), object(6)\n",
      "memory usage: 205.6+ KB\n"
     ]
    }
   ],
   "source": [
    "bb_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bb_original_1 = pd.read_csv(\"../assets/bill.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb_original_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "94514384-cf79-4e7a-a09b-02cddc91e77c"
   },
   "source": [
    "##### Write a brief description of your data, data dictionary, and any interesting observations you've made thus far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "33a9e3f0-a29d-4b02-90bd-528bdb44fb78"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "888b6223-3bb4-4d91-b753-4867a3a1b281"
   },
   "source": [
    "## Step 2: Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "8a273328-6d9f-4dfc-88f8-a0c18e4d7f90"
   },
   "source": [
    "##### Do some rudimentary cleaning. Rename any columns that are poorly named, shorten any strings that are too long, and check for missing values (replace them and explain rationale if it makes sense)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "00022458-8edc-4f84-8492-0be04397fa64"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "604ee5d7-10ed-4d14-9f86-16a6b240c00d"
   },
   "source": [
    "##### Using Pandas' built in `melt` function, pivot the weekly ranking data to be long rather than wide. As a result, you will have removed the 72 'week' columns and replace it with two: Week and Ranking. There will now be multiple entries for each song, one for each week on the Billboard rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "bf0161ca-0fcb-4883-a216-93fd7ffa6456"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "2023c5a8-1f4e-4d83-9a52-c41a5090af74"
   },
   "source": [
    "## Step 3: Visualize your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "dfaca026-8eca-4119-b4c1-e43433790c8e"
   },
   "source": [
    "##### Using BOTH a Tableau Dashboard and python, create visualizations that will provide context to your data. There is no minimum or maximum number of graphs you should generate, but there should be a clear and consistent story being told. Give insights to the distribution, statistics, and relationships of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "aa0c535c-497c-4f10-b695-540612ca534e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "8401c631-245b-4560-8971-25cb2406c2ab"
   },
   "source": [
    "## Step 4: Create a Problem Statement.\n",
    "\n",
    "##### Having explored the data, come up with a problem statement that includes risks and assumptions for this data set. You can feel free to introduce data from any other source to support your problem statement, just be sure to provide a link to the origin of the data. Once again- be creative!\n",
    "\n",
    "- Guide: http://www.ceptara.com/blog/how-to-write-problem-statement\n",
    "- Kaggle example: https://www.kaggle.com/c/inria-bci-challenge\n",
    "- Kaggle example: https://www.kaggle.com/c/axa-driver-telematics-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "e1b81214-9b26-4735-8c1b-4482e948b355"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "a0ff30a0-48be-4851-9ec3-4ce8ece08a67"
   },
   "source": [
    "## Step 5: Brainstorm your Approach.\n",
    "##### In bullet-list form, provide a proposed approach for evaluating your problem statement. This can be somewhat high-level, but start to think about ways you can massage the data for maximum efficacy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "9d772c7b-61e0-4bc4-bb1a-f3d43ba54862"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a3c74c5b-3d90-4442-97d9-ae320fe238d1"
   },
   "source": [
    "## Step 6: Create a blog post with your code snippets and visualizations.\n",
    "##### Data Science is a growing field, and the Tech industry thrives off of collaboration and sharing of knowledge. Blogging is a powerful means for pushing the needle forward in our field. Using your blogging platform of choice, create a site and post your process and results. Rather than writing a procedural text, imagine you're describing the data, visualizations, and conclusions you've arrived at to your peers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "9b0185e4-7023-4086-b8b7-e15bcacc9984"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "aee61cbf-dfe9-40d3-bfef-772a60bed757"
   },
   "source": [
    "### BONUS: LinkedIn has recognized you as a DS thought leader and asked you to pen a white paper (~500 words) on 'Best Practices for Clean Data'. This will be an opinion piece read by a wide (including semi-technical) audience, so be sure to back up your statements with real world examples or scenarios.\n",
    "\n",
    "##### Hint: Look for online resources (articles, blogs, papers, youtube, podcasts, reddit) that will help you understand the challenges and implications of dealing with big data and missing data. This should be a personal reflection on everything you've learned this week, and the learning goals that have been set out for you going forward. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "28deb393-c994-47bc-87d2-035741ce527c"
   },
   "source": [
    "Score | /24\n",
    "----- | ------\n",
    "Identify: Problem Statement / Hypothesis\t| \t\t\n",
    "Identify: Risks & Assumptions\t\t\t\t| \n",
    "Acquire: Import Data Using Pandas\t\t\t| \n",
    "Parse: Perform EDA Using Pandas\t\t\t\t| \n",
    "Viz: Tableau Dashboard and Plots\t\t\t| \n",
    "Mine: Determine Correlations\t\t\t\t|\n",
    "Refine: Evaluate Findings\t\t\t\t    |\n",
    "Present: Describe Results in Blog Post\t\t|\n",
    "Bonus! Present: Write a short White Paper\t| /5"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
